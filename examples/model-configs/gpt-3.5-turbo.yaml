backend: llama-stable
context_size: 1024
name: gpt-3.5-turbo
parameters:
  model: gpt4all-snoozy-13b-superhot-8k.ggmlv3.q4_K_S.bin
  temperature: 0.2
  top_k: 80
  top_p: 0.7
template:
  chat: gpt-3.5-turbo-chat
  completion: gpt-3.5-turbo-completion

